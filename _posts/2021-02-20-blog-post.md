---
title: 'EKF SLAM Demo'
date: 2021-02-20
permalink: /posts/2021/02/20/blog-post/
mathjax: true
tags:
  - Extended Kalman Filter
  - SLAM
---

### Chicken or the egg?

In robotics, it is common to use a map of the environment as a tool for navigation and motion planning. Specifically, maps are really good at telling you where you are in the environment: this called localization. The ability to localize, though, is completely dependent on the quality of the map. Humans could construct this map, but you can imagine how much work that would require to measure out every detail. If the map is off by a little bit, how long will it take to correct that error and improve precision? What if something changes and you need to update the map? Since robots will use the map anyway, there is this idea of use the sensing modality of the robot to build the map: this is called mapping.

One issue that you may see is that in a realistic situation, there seems to be some conflicting workflow: in order to create a map, the robot needs a precise estimate on its current location (how can you tell the size of a room if you aren't confident in how far you walked from one end to the other?). But in order to get a precise estimate on the current location, you must have a map to help you localize. In this sense, _S_imultaneous _L_oclalization _a_nd _M_apping (SLAM) is often described as a chicken-and-the-egg problem, where the solution of one process requires the end result to the other. How do you solve such a problem?

The answer is not too complicated: you must solve both problems at the same time -- hence the world "simultaneous". The idea is that separately, mapping and localization are pretty much the same process of estimating location given some process within some errors. In localization, you estimate your current position by knowing the exact position of landmarks on the map, and when mapping, you estimate the location of landmarks given a precise estimate of you current location. SLAM leans into the mathy jungle of Baysean estimation by recognizing that since the estimation process is the same, you can effectively lump all the positions that you want to estimate (robot and landmarks) into the same vector. By iteratively finding estimates for this vector, you solve both localization and mapping at the same time.

This blog post will focus on the most conceptually simple type of SLAM, called EKF SLAM. If you are not aware, the [EKF (Extended Kalman Filter)](https://en.wikipedia.org/wiki/Extended_Kalman_filter) is way of estimating values of any variable that (1) follows a differential equation of motion through time, allowing you to predict the current value from previous values, and (2) is periodically observed, allowing you to correct you're prediction with measurements. This post will not be an explanation of how EKF SLAM works, per se, as there are many works that already do this quite well ([here](https://www.youtube.com/watch?v=X30sEgIws0g) is a video by Cyrill Stanchniss, whose youtube channel is a rich resource for any aspiring roboticist). Instead, I'll will explore some questions that are often left unexplored when EKF SLAM is talked about, as well as show you my personal implementation of the 2D EKF SLAM for robots with an odometry motion model.

### The 1D SLAM Problem

First, let's look at the simple 1D case, i.e., robot movement on a straight line. It would look funny if the landmarks were on the robot's line of motion, so without loss of generality I'll put the landmarks and the robot on different y positions, and allow the robot to change its x position by moving right to left. Below is a picture of the setup with two landmarks:

<p align="center">
  <img width="460" height="300" src="/images/blog_pics/2021/EKF_SLAM/1D_setup.png">
</p>

Since the robot can only move left and right, the motion model of the robot is quite simple. Here is the discrete motion dynamics that describe how the x position of the robot $x_r$ changes under commanded velocity $u$ over a time step of $dt$:

\begin{equation}\label{eq:motion_model}
x_r^+ = x_r + u\times dt
\end{equation}

The robot can only observe a landmark if it is within some sensing radius. Because this is a 1D simulation, I am only concerned with the x position of landmark $i$, denoted as $x_{li}$. When a landmark is observed, the robot observes the relative distances between it and the landmark:

\begin{equation}\label{eq:meas_model}
z_{li} = x_{li} - x_r
\end{equation}

Both the robotic motion \ref{eq:motion_model} and the measurement model \ref{eq:meas_model} are linear, so the EKF performs the same as the regular KF in this situation. This won't be the case for the 2D EKF SLAM in the next section, but for now the linearity keeps the problem simple enough to see the concepts at play without too much complication.

In this simplified SLAM problem, we wish to estimate the x positions of the robot and the two landmarks, so three variables in total. In the EKF algorithm, our belief takes the form of a multivariate gaussian. This gaussian is defined by its average value $\mathbf{\mu}$, where we actually estimate the x positions to be, and the covariance matrix $\Sigma$, which defines the errors in this belief (along the diagonal) as well as the correlations between the x positions (on the off-diagonal elements). In general, these are defined as:

\begin{equation}
\mathbf{\mu} = 
\begin{pmatrix}
\mu_{rx} \\\\\\
\mu_{1x} \\\\\\
\mu_{2x}
\end{pmatrix}
\end{equation}

\begin{equation}
\mathbf{\Sigma} = 
\begin{pmatrix}
\Sigma_{rr} & \Sigma_{r1} & \Sigma_{r2} \\\\\\
\Sigma_{1r} & \Sigma_{11} & \Sigma_{12} \\\\\\
\Sigma_{2r} & \Sigma_{21} & \Sigma_{22}
\end{pmatrix}
\end{equation}

To be clear, $\Sigma_{ri}$ is the covariance between the robot's x position and the $i$th landmark's x position.

Initializing the EKF SLAM process is pretty simple. First, we provide a estimate on the locations of the robot and landmarks, $\mathbf{\mu}$. As is the case with regular EKF estimation, these starting estimates are not so critical. I chose $\mathbf{\mu} = \begin{pmatrix} 0 & 0 & 0 \end{pmatrix}^T$. There is small but important point when choosing $\Sigma$: since SLAM is concerned with building a map of the environment, the origin can be defined however we choose. We can take advantage of this choice by saying that the origin is _precisely where the robot starts_. In terms of the mutlivariate gaussian, $\Sigma_{rr}=0$. The other landmarks are initialized with a large error, say $\Sigma_{ii}=100$.

Below is a gif showing how the estimates and uncertainties change over time in the simulation. A line is drawn between the robot and any landmark that it is close enough to observe.

<p align="center">
  <img width="460" height="300" src="/images/blog_pics/2021/EKF_SLAM/1D_EKF.gif">
</p>

Here are some observations that one can make:
- When the robot moves without sensing a landmark, it's uncertainty grows over time.
- Unless observed by the robot, the uncertainty of the landmarks _do not_ change over time.
- When the robot sees a landmark for the first time, the uncertainty of the landmark is the uncertainty of the robot at that moment. At the same time, the uncertainty of the robot doesn't really change.

There are two "magic" things that happen in EKF SLAM. The first happens when the robot sees a landmark it has already seen before. Since the uncertainty of the landmarks don't grow over time, sensing the landmark for a second time helps reduce the robot's own uncertainty. It is unlikely that this exchange will reduce the uncertainty of the landmark, since the robot's uncertainty only grows as it moves without observing any landmarks.

The second bit EKF SLAM magic is even more interesting. In the above gif, you may notice that the uncertainty of the landmark 2 is fairly large when first observed. This makes sense, since the robot itself has a large uncertainty. Continue watching, and you'll see that the uncertainty of landmark 2 decreases when landmark 1 is observed for a second time! This is strange at first: why should the uncertainty of one landmark be reduced when another landmark is observed? Further thought reveals the intuition: seeing a landmark for a second time helps contextualize the locations of the other landmarks you observed in the past. Imagine walking around an unfamiliar neighborhood; seeing a landmark for a second time not only helps you understand where you are, but also helps place the landmarks that you recently walked past. Since you typically see landmarks again only after travelling around a complete loop, this process is called _closing the loop_.

In the parlance of Gaussian shapes, we say that the locations of the landmarks are _correlated_. These are the off-diagonal elements of $\Sigma$ (technically the off-diagonal elements are called covariances, but they are strongly related to correlation). Initially, the locations of landmarks are uncorrelated in the EKF, i.e., $\Sigma$ is a diagonal matrix. When landmarks are first observed, the off-diagonal entries of $\Sigma$ are filled by the EKF algorithm. It's these off-diagonal correlations that reduce the uncertainty of landmarks when other landmarks are observed.

The correlations between robot location and landmark location aren't shown in the above figure, since the correlation isn't as straight forward to visualize. To help visualize how these correlations are built up, below the simulation along with the covariance matrix $\Sigma$ overtime.

<p align="center">
  <img width="750" height="400" src="/images/blog_pics/2021/EKF_SLAM/1D_EKF_wSigma.gif">
</p>

### The 2D SLAM Problem

<p align="center">
  <img width="750" height="400" src="/images/blog_pics/2021/EKF_SLAM/ekf_slam_2D.gif">
</p>


<!-- ### How do you fuse measurements together?

The first time you learn about probabilistic robotics, you will probably hear about the [Kalman filter](https://en.wikipedia.org/wiki/Kalman_filter). The Kalman filter is a way of estimating the state of a system that has both process noise and measurement noise. Founded in probability theory, it gives an optimal estimate based on the relative size of the process and measurement noise. If the process noise is very large and the measurement noise is very small, then the Kalman filter returns an estimated state that is closer to the measurement, and vice versa. For most students that first encounter the Kalman filter, you're told the intuition, shown some complicated multivariate Gaussian math and are told to use it in a homework exercise.

Most introductory examples of the Kalman filter have only one measurement to use. What if there are more than one, though? How do you handle two different measurements of the same exact thing with a Kalman filter? This is a form of sensor fusion, and when I first learned the Kalman filter I had only a shaky understanding of the solution. The purpose of this blog post is to show how the Kalman filter can perform sensor fusion, and hopefully clarify the machinery of the Kalman filter in the process.

### The two steps of the Kalman filter

Let us define $p(\mathbf{x})$ as the belief probability distribution of state space vector $\mathbf{x}$. A Kalman filter has two important steps when providing an estimate of the value of $\mathbf{x}$:
 - Prediction update step (use input $\mathbf{u}$ to update $p(\mathbf{x})$)
 - Measurement update step (use measurement $\mathbf{y}$ to update $p(\mathbf{x})$)

Since the Kalman filter assumes multivariate Gaussian probability distributions, only two quantities are recorded over each step $k$ in the Kalman filter: an estimate vector $\hat{\mathbf{x}}\_k$ (corresponding to the mean of the Gaussian), and a covariance matrix $P\_k$ (corresponding to the confidence of the measurement). Together, these quantities fully define the probability distribution $p(\mathbf{x})$, so when the Kalman filter updates $p(\mathbf{x})$ in the prediction and the measurement step, it really just updates these two variables.

What if we have two separate measurements $\mathbf{y}^a$ and $\mathbf{y}^b$, modeled with their own Gaussian noise? Cutting to the punchline, you perform _two_ measurement steps, one with each measurement:
 - Prediction update step (use input $\mathbf{u}$ to update $p(\mathbf{x})$)
 - First measurement update step (use measurement $\mathbf{y}^a$ to update $p(\mathbf{x})$)
 - Second measurement update step (use measurement $\mathbf{y}^b$ to update $p(\mathbf{x})$)

This seems like a natural thing to do given two different measurements. Let's see why this is so.

### The Bayes Update

The Kalman filter is a specific type of filter called a Bayes filter. The Bayes filter also has two steps: one prediction step and one measurement step. In order to change the Kalman filter to incorporate more than one measurement step, we need to understand what each step means in terms of Bayesian estimation. 

Define the belief distribution at iteration $k-1$ as $p\_{k-1\|k-1}(\mathbf{x})$. The $k-1\|k-1$ part can be read as the probability distribution at time $k-1$, given information up to time $k-1$. The prediction step requires some process model that describes the probability of reaching state $\mathbf{x}^+$ given current state $\mathbf{x}$ and input $\mathbf{u}_{k-1}$:

\begin{equation\*}
p(\mathbf{x}^+\|\mathbf{x},\mathbf{u}_{k-1})
\end{equation\*}

The prediction update is thus described in the Bayes filter as:

\begin{equation}
p\_{k\|k-1}(\mathbf{x}) = \sum\_{\mathbf{x}'} p(\mathbf{x}\|\mathbf{x}',\mathbf{u}_{k-1}) p\_{k-1\|k-1}(\mathbf{x})
\end{equation}

At time step $k$, we then receive two measurements $\mathbf{y}^a_k$ and $\mathbf{y}^b_k$. The measurement update of the Bayes filter is then used to find the probability distribution of the state given these two measurements, or $p\_{k\|k}(\mathbf{x})=p(\mathbf{x}\|\mathbf{y}^a_k,\mathbf{y}^b_k)$. In the case of a single measurement, Bayes' rule is used to "switch" the random variable and the conditioned variable:

\begin{equation\*}
p(\mathbf{x}\|\mathbf{y}) = \eta p(\mathbf{y}\|\mathbf{x})p\_{k\|k-1}(\mathbf{x})
\end{equation\*}

The $\eta$ term is a normalization factor, and we are usually unconcerned with it in almost all Bayes filters. The measurement process $p(\mathbf{y}^a\|\mathbf{x})$ includes gaussian noise in the Kalman filter, and the probability distribution $p_{k\|k-1}(\mathbf{x})$ is found in the prediction update.

With two state measurements, this update is only slightly altered. First, perform Bayes' rule between the state variable $\mathbf{x}$ and a single measurement, say $\mathbf{y}^b$:

\begin{equation\*}
p(\mathbf{x}\|\mathbf{y}^a\_k,\mathbf{y}^b\_k) = \eta^b p(\mathbf{y}^b\_k\|\mathbf{x},\mathbf{y}^a\_k)p\_{k\|k-1}(\mathbf{x}\|\mathbf{y}^a\_k)
\end{equation\*}

We can simplify this expression by making the reasonable assumption that the measurement model for $\mathbf{y}^b_k$ is independent of (1) the iteration step $k$ and (2) the value of the other measurement $\mathbf{y}^a$, so that $p(\mathbf{y}^b\_k\|\mathbf{x},\mathbf{y}^a\_k) = p(\mathbf{y}^b\|\mathbf{x})$. This results in:

\begin{equation} \label{eq:second_measurement}
p(\mathbf{x}\|\mathbf{y}^a\_k,\mathbf{y}^b\_k) = \eta^b p(\mathbf{y}^b\|\mathbf{x})p\_{k\|k-1}(\mathbf{x}\|\mathbf{y}^a\_k)
\end{equation}

This is great, but we still need $p\_{k\|k-1}(\mathbf{x}\|\mathbf{y}^a\_k)$, or the probability distribution of $\mathbf{x}$ conditioned on the value for $\mathbf{y}^a_k$. This term can be found performing Bayes' rule a second time:

\begin{equation} \label{eq:first_measurement}
p(\mathbf{x}\|\mathbf{y}^a\_k) = \eta^a p(\mathbf{y}^a\|\mathbf{x})p\_{k\|k-1}(\mathbf{x})
\end{equation}

Eq. \ref{eq:first_measurement} can be thought of as the first measurement update to find the a posteriori probability distribution with respect to measurement $\mathbf{y}^a$. We then take this updated distribution and perform a second measurement update with this update distribution and $\mathbf{y}^b$ and in Eq. \ref{eq:second_measurement}. The result is an estimate that "fuses" two different measurements from different sensor, verifying our intuition.

### One final note

It should be that incorporating two different measurements should arrive at the same answer, independent of the order in which you incorporate the measurements. Indeed, you can see this by substituting Eq. \ref{eq:first_measurement} into Eq. \ref{eq:second_measurement}:

\begin{equation}
p(\mathbf{x}\|\mathbf{y}^a\_k,\mathbf{y}^b\_k) = \eta^a\eta^b p(\mathbf{y}^a\|\mathbf{x})p(\mathbf{y}^b\|\mathbf{x})p\_{k\|k-1}(\mathbf{x})
\end{equation}

The measurement update is symmetric in the label for measurements $a$ and $b$, so it cannot depend on the order in which the measurement updates are applied. -->